#!/usr/bin/env python3
"""
ì´ì¬ëª… í‚¤ì›Œë“œ ì‹¤ì‹œê°„ ì»¤ë®¤ë‹ˆí‹° ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
- ëŒ€ìƒ: í´ë¦¬ì•™, ë½ë¿Œ, ë”ì¿ , ë³¼ë² ë“œë¦¼
- ì£¼ê¸°: 15ë¶„
- ì•Œë¦¼: í…”ë ˆê·¸ë¨
"""

import requests
import json
import time
import hashlib
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import feedparser
import re
from urllib.parse import quote

# ì„¤ì •
CONFIG = {
    "keyword": "ì´ì¬ëª…",
    "interval_minutes": 15,
    "telegram_token": None,  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
    "telegram_chat_id": None,  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
    "seen_posts_file": "/Users/roturnjarvis/.openclaw/workspace/logs/seen_posts.json",
    "log_file": "/Users/roturnjarvis/.openclaw/workspace/logs/community_monitor.log"
}

# í—¤ë” (ë´‡ ì°¨ë‹¨ íšŒí”¼)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
    'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
}

class CommunityMonitor:
    def __init__(self):
        self.seen_posts = self.load_seen_posts()
        self.session = requests.Session()
        self.session.headers.update(HEADERS)
        
    def load_seen_posts(self):
        """ì´ë¯¸ ë³¸ ê²Œì‹œë¬¼ ë¡œë“œ"""
        try:
            with open(CONFIG['seen_posts_file'], 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except (FileNotFoundError, json.JSONDecodeError):
            return set()
    
    def save_seen_posts(self):
        """ë³¸ ê²Œì‹œë¬¼ ì €ì¥"""
        import os
        os.makedirs(os.path.dirname(CONFIG['seen_posts_file']), exist_ok=True)
        with open(CONFIG['seen_posts_file'], 'w', encoding='utf-8') as f:
            json.dump(list(self.seen_posts), f, ensure_ascii=False)
    
    def generate_post_id(self, title, url, source):
        """ê²Œì‹œë¬¼ ê³ ìœ  ID ìƒì„± (ì¤‘ë³µ ì œê±°ìš©)"""
        content = f"{source}:{title}:{url}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def send_telegram(self, message):
        """í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡"""
        token = os.getenv('TELEGRAM_BOT_TOKEN')
        chat_id = os.getenv('TELEGRAM_CHAT_ID')
        
        if not token or not chat_id:
            print(f"[ì•Œë¦¼] í…”ë ˆê·¸ë¨ ì„¤ì • ì—†ìŒ: {message[:100]}...")
            return
        
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        payload = {
            'chat_id': chat_id,
            'text': message,
            'parse_mode': 'HTML',
            'disable_web_page_preview': True
        }
        
        try:
            response = requests.post(url, json=payload, timeout=10)
            return response.json()
        except Exception as e:
            print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    def log(self, message):
        """ë¡œê·¸ ê¸°ë¡"""
        import os
        os.makedirs(os.path.dirname(CONFIG['log_file']), exist_ok=True)
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_msg = f"[{timestamp}] {message}"
        print(log_msg)
        with open(CONFIG['log_file'], 'a', encoding='utf-8') as f:
            f.write(log_msg + '\n')

    def fetch_clien(self):
        """í´ë¦¬ì•™ ì •ì¹˜/ì‚¬íšŒ ê²Œì‹œíŒ"""
        posts = []
        try:
            # í´ë¦¬ì•™ RSS
            url = f"https://www.clien.net/service/board/park?&od=T31&po=0"
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            items = soup.find_all('span', class_='subject_fixed')
            for item in items[:10]:  # ìµœê·¼ 10ê°œë§Œ
                title = item.get_text(strip=True)
                if CONFIG['keyword'] in title:
                    link_elem = item.find_parent('a')
                    if link_elem:
                        href = link_elem.get('href', '')
                        full_url = f"https://www.clien.net{href}" if href.startswith('/') else href
                        posts.append({
                            'source': 'í´ë¦¬ì•™',
                            'title': title,
                            'url': full_url,
                            'time': datetime.now().strftime('%H:%M')
                        })
            
            time.sleep(2)  # rate limiting
        except Exception as e:
            self.log(f"í´ë¦¬ì•™ ì˜¤ë¥˜: {e}")
        
        return posts

    def fetch_ppomppu(self):
        """ë½ë¿Œ ì •ì¹˜ ììœ ê²Œì‹œíŒ"""
        posts = []
        try:
            url = "http://www.ppomppu.co.kr/zboard/zboard.php?id=freeboard"
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ë½ë¿ŒëŠ” í…Œì´ë¸” êµ¬ì¡°
            rows = soup.find_all('tr', class_=['list1', 'list0'])
            for row in rows[:15]:
                title_elem = row.find('td', class_='eng list_vspace')
                if title_elem:
                    link = title_elem.find('a')
                    if link:
                        title = link.get_text(strip=True)
                        if CONFIG['keyword'] in title:
                            href = link.get('href', '')
                            posts.append({
                                'source': 'ë½ë¿Œ',
                                'title': title,
                                'url': href if href.startswith('http') else f"http://www.ppomppu.co.kr/zboard/{href}",
                                'time': datetime.now().strftime('%H:%M')
                            })
            
            time.sleep(2)
        except Exception as e:
            self.log(f"ë½ë¿Œ ì˜¤ë¥˜: {e}")
        
        return posts

    def fetch_theqoo(self):
        """ë”ì¿  ì •ì¹˜/ì‚¬íšŒ"""
        posts = []
        try:
            # ë”ì¿ ëŠ” ê²€ìƒ‰ ê¸°ëŠ¥ ì‚¬ìš©
            encoded_keyword = quote(CONFIG['keyword'])
            url = f"https://theqoo.net/index?mid=hot&search_keyword={encoded_keyword}&search_target=title"
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            items = soup.find_all('td', class_='title')
            for item in items[:10]:
                link = item.find('a')
                if link:
                    title = link.get_text(strip=True)
                    href = link.get('href', '')
                    posts.append({
                        'source': 'ë”ì¿ ',
                        'title': title,
                        'url': href if href.startswith('http') else f"https://theqoo.net{href}",
                        'time': datetime.now().strftime('%H:%M')
                    })
            
            time.sleep(2)
        except Exception as e:
            self.log(f"ë”ì¿  ì˜¤ë¥˜: {e}")
        
        return posts

    def fetch_bobaedream(self):
        """ë³´ë°°ë“œë¦¼ ì •ì¹˜ ê²Œì‹œíŒ"""
        posts = []
        try:
            url = "https://www.bobaedream.co.kr/list?code=politic"
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            items = soup.find_all('a', class_='bsubject')
            for item in items[:15]:
                title = item.get_text(strip=True)
                if CONFIG['keyword'] in title:
                    href = item.get('href', '')
                    posts.append({
                        'source': 'ë³´ë°°',
                        'title': title,
                        'url': href if href.startswith('http') else f"https://www.bobaedream.co.kr{href}",
                        'time': datetime.now().strftime('%H:%M')
                    })
            
            time.sleep(2)
        except Exception as e:
            self.log(f"ë³´ë°° ì˜¤ë¥˜: {e}")
        
        return posts

    def analyze_sentiment(self, title):
        """ê°„ë‹¨í•œ ê°ì„± ë¶„ì„"""
        positive_words = ['ì§€ì§€', 'ì‘ì›', 'í™˜í˜¸', 'ìŠ¹ë¦¬', 'ìš°ì„¸', 'í˜¸ì¬']
        negative_words = ['ë¹„íŒ', 'ë¬¸ì œ', 'ë…¼ë€', 'ì˜í˜¹', 'í”¼í•´', 'ë°˜ëŒ€', 'ì•…ì¬', 'í˜•', 'ì¬íŒ', 'êµ¬ì†']
        
        pos_count = sum(1 for word in positive_words if word in title)
        neg_count = sum(1 for word in negative_words if word in title)
        
        if pos_count > neg_count:
            return 'ê¸ì •'
        elif neg_count > pos_count:
            return 'ë¶€ì •'
        else:
            return 'ì¤‘ë¦½'

    def categorize_post(self, title):
        """ê²Œì‹œë¬¼ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        categories = {
            'ì •ì±…': ['ì •ì±…', 'ë²•ì•ˆ', 'ì˜ˆì‚°', 'ì„¸ê¸ˆ', 'ë³µì§€', 'ë¶€ë™ì‚°', 'ì£¼íƒ'],
            'ì‚¬ë²•': ['ì¬íŒ', 'í˜•', 'êµ¬ì†', 'ê¸°ì†Œ', 'ê²€ì°°', 'ë²•ì›', '1ì‹¬', '2ì‹¬'],
            'ì •ì¹˜': ['ë‹¹', 'ì§€ì§€ìœ¨', 'ì„ ê±°', 'ëŒ€í‘œ', 'ì´ì¬ëª…', 'ë¯¼ì£¼ë‹¹', 'êµ­í˜'],
            'ê²½ì œ': ['ì£¼ì‹', 'ì¦ì‹œ', 'ê¸°ì—…', 'ê²½ì œ', 'íˆ¬ì'],
            'ì‚¬íšŒ': ['ë…¼ë€', 'ì‚¬ê±´', 'ì‚¬ê³ ', 'ì—¬ë¡ ']
        }
        
        for cat, keywords in categories.items():
            if any(kw in title for kw in keywords):
                return cat
        return 'ê¸°íƒ€'

    def run(self):
        """ë©”ì¸ ì‹¤í–‰"""
        self.log(f"ëª¨ë‹ˆí„°ë§ ì‹œì‘: í‚¤ì›Œë“œ '{CONFIG['keyword']}'")
        
        all_posts = []
        
        # ê° ì‚¬ì´íŠ¸ ìˆ˜ì§‘
        all_posts.extend(self.fetch_clien())
        all_posts.extend(self.fetch_ppomppu())
        all_posts.extend(self.fetch_theqoo())
        all_posts.extend(self.fetch_bobaedream())
        
        # ì¤‘ë³µ ì œê±° ë° í•„í„°ë§
        new_posts = []
        for post in all_posts:
            post_id = self.generate_post_id(post['title'], post['url'], post['source'])
            if post_id not in self.seen_posts:
                self.seen_posts.add(post_id)
                post['sentiment'] = self.analyze_sentiment(post['title'])
                post['category'] = self.categorize_post(post['title'])
                new_posts.append(post)
        
        # ì €ì¥
        self.save_seen_posts()
        
        # ê²°ê³¼ ì¶œë ¥ ë° ì•Œë¦¼
        if new_posts:
            self.log(f"ì‹ ê·œ ê²Œì‹œë¬¼ {len(new_posts)}ê°œ ë°œê²¬")
            
            # ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
            summary = f"ğŸ” <b>ì´ì¬ëª… í‚¤ì›Œë“œ ì•Œë¦¼</b>\n"
            summary += f"â° {datetime.now().strftime('%H:%M')} ê¸°ì¤€\n"
            summary += f"ğŸ“Š ì‹ ê·œ {len(new_posts)}ê°œ\n\n"
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì •ë ¬
            by_category = {}
            for post in new_posts:
                cat = post['category']
                if cat not in by_category:
                    by_category[cat] = []
                by_category[cat].append(post)
            
            for cat, posts in by_category.items():
                summary += f"<b>[{cat}]</b>\n"
                for post in posts[:3]:  # ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 3ê°œ
                    emoji = {'ê¸ì •': 'ğŸŸ¢', 'ë¶€ì •': 'ğŸ”´', 'ì¤‘ë¦½': 'âšª'}[post['sentiment']]
                    summary += f"{emoji} [{post['source']}] {post['title'][:40]}...\n"
                    summary += f"   â”” {post['url'][:60]}...\n"
                summary += "\n"
            
            # ì „ì²´ í†µê³„
            sentiment_counts = {}
            for post in new_posts:
                s = post['sentiment']
                sentiment_counts[s] = sentiment_counts.get(s, 0) + 1
            
            summary += f"<b>ê°ì„± ë¶„í¬:</b> "
            summary += f"ê¸ì • {sentiment_counts.get('ê¸ì •', 0)} | "
            summary += f"ë¶€ì • {sentiment_counts.get('ë¶€ì •', 0)} | "
            summary += f"ì¤‘ë¦½ {sentiment_counts.get('ì¤‘ë¦½', 0)}"
            
            print("\n" + "="*60)
            print(summary)
            print("="*60)
            
            # í…”ë ˆê·¸ë¨ ì „ì†¡
            self.send_telegram(summary)
        else:
            self.log("ì‹ ê·œ ê²Œì‹œë¬¼ ì—†ìŒ")
        
        return new_posts

if __name__ == "__main__":
    import os
    monitor = CommunityMonitor()
    monitor.run()
